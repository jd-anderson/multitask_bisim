{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec30c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cvxpy as cp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import control\n",
    "from scipy.linalg import solve_discrete_are, solve_discrete_lyapunov, block_diag\n",
    "import mosek\n",
    "from scipy.signal import cont2discrete\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd304eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_m_l_pairs(H):\n",
    "    m_samples = np.random.uniform(low=.1, high=.5, size=(H, 1))\n",
    "    l_samples = np.random.uniform(low=.5, high=1, size=(H, 1))\n",
    "    m_l_pairs = np.hstack((m_samples, l_samples))\n",
    "    return m_l_pairs\n",
    "\n",
    "def sample_q_r_pairs(H):\n",
    "    q_samples = np.random.uniform(low=.1, high=.5, size=(H, 1))\n",
    "    r_samples = np.random.uniform(low=0.01, high=0.05, size=(H, 1))\n",
    "    q_r_pairs = np.hstack((q_samples, r_samples))\n",
    "    return q_r_pairs\n",
    "\n",
    "def inverted_pendulum(m, l, dt=0.05):\n",
    "    g = 10\n",
    "    A = np.array([[1, dt],\n",
    "                  [(g/l)*dt, 1]])\n",
    "    B = np.array([[0],\n",
    "                  [dt/(m*(l**2))]])\n",
    "    return A, B\n",
    "\n",
    "def dlqr(A, B, Q, R):\n",
    "    P = solve_discrete_are(A, B, Q, R)\n",
    "    K = np.linalg.inv(R + B.T @ P @ B) @ (B.T @ P @ A)\n",
    "    return K\n",
    "\n",
    "\n",
    "def squared_grad_heter_bisim_bound(K,Sigma_0,A1,B1,Q1,R1,A2,B2,Q2,R2):\n",
    "    A1_K = A1-B1@K\n",
    "    A2_K = A2-B2@K\n",
    "\n",
    "    assert max(abs(np.linalg.eigvals(A1-B1@K)))<1, \"Kn is not a stabilizing controller for system i\"\n",
    "    assert max(abs(np.linalg.eigvals(A2-B2@K)))<1, \"Kn is not a stabilizing controller for system j\"\n",
    "\n",
    "    # Find a lambda that retains stability\n",
    "    A_K = block_diag(A1_K,A2_K)\n",
    "    lambda_ = np.round(.5*(1-(max(abs(np.linalg.eigvals(A_K))))**2)-1e-5,5)\n",
    "    \n",
    "    print(\"Chosen lambda:\",lambda_)\n",
    "    P1_K = solve_discrete_lyapunov(A1_K.T,Q1+K.T@R1@K)\n",
    "    P2_K = solve_discrete_lyapunov(A2_K.T,Q2+K.T@R2@K)\n",
    "\n",
    "    E1_K = (R1+B1.T@P1_K@B1)@K-B1.T@P1_K@A1\n",
    "    E2_K = (R2+B2.T@P2_K@B2)@K-B2.T@P2_K@A2\n",
    "    C_K = 2*np.hstack([E1_K,-E2_K])\n",
    "\n",
    "    # Compute M via optimization problem\n",
    "    n = Sigma_0.shape[0]\n",
    "    M = cp.Variable((2*n,2*n),PSD=True)\n",
    "    M1 = cp.Variable((n,n),PSD=True)\n",
    "    M2 = cp.Variable((n,n),PSD=True)\n",
    "    C_K = 2*cp.hstack([E1_K,-E2_K])\n",
    "    t = cp.Variable()\n",
    "    s = cp.Variable(nonneg=True)\n",
    "    u = cp.Variable(nonneg=True)   # epigraph variable for objective\n",
    "\n",
    "    # Constraints\n",
    "    constraints = []\n",
    "    constraints += [M - s * np.eye(2*n) >> 0]    # M >= s I  => s <= lambda_min(M)\n",
    "    constraints += [t == cp.trace((M1+M2)@Sigma_0)]      # linear relation\n",
    "    t_tilde = (np.sqrt(2) * t) / (2.0 * lambda_)\n",
    "    # rotated SOC form: || [2*t_tilde; u - s] ||_2 <= u + s\n",
    "    constraints += [cp.norm(cp.vstack([2*t_tilde, u - s]), 2) <= u + s]  \n",
    "    constraints += [s>=1e-6,M>>C_K.T@C_K,A_K.T@M@A_K<<(1-2*lambda_)*M] #M>=1e-5*np.eye(2*n),\n",
    "    constraints += [M[:n,:n]==M1,M[n:,n:]==M2] #,M[:n,n:] == 0,M[n:,:n] == 0]\n",
    "\n",
    "    objective = cp.Minimize(u)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS) \n",
    "\n",
    "    if prob.status not in [\"infeasible\", \"unbounded\"]:\n",
    "        M = np.round(M.value)\n",
    "        M1 = np.round(M1.value,10)\n",
    "        M2 = np.round(M2.value,10)\n",
    "\n",
    "        bound = prob.value\n",
    "        return bound\n",
    "    else:\n",
    "        raise ValueError(\"Problem status: \" + prob.status)\n",
    "\n",
    "def new_squared_grad_heter_bisim_bound(K,Sigma_0,A1,B1,Q1,R1,A2,B2,Q2,R2):\n",
    "    A1_K = A1-B1@K\n",
    "    A2_K = A2-B2@K\n",
    "\n",
    "    assert max(abs(np.linalg.eigvals(A1-B1@K)))<1, \"Kn is not a stabilizing controller for system i\"\n",
    "    assert max(abs(np.linalg.eigvals(A2-B2@K)))<1, \"Kn is not a stabilizing controller for system j\"\n",
    "\n",
    "    # Find a lambda that retains stability\n",
    "    A_K = block_diag(A1_K,A2_K)\n",
    "    lambda_ = np.round(.5*(1-(max(abs(np.linalg.eigvals(A_K))))**2)-1e-5,5)\n",
    "\n",
    "    print(\"Chosen lambda:\",lambda_)\n",
    "    P1_K = solve_discrete_lyapunov(A1_K.T,Q1+K.T@R1@K)\n",
    "    P2_K = solve_discrete_lyapunov(A2_K.T,Q2+K.T@R2@K)\n",
    "\n",
    "    E1_K = (R1+B1.T@P1_K@B1)@K-B1.T@P1_K@A1\n",
    "    E2_K = (R2+B2.T@P2_K@B2)@K-B2.T@P2_K@A2\n",
    "    C_K = 2*np.hstack([E1_K,-E2_K])\n",
    "\n",
    "\n",
    "\n",
    "    # Compute M via optimization problem\n",
    "    n = Sigma_0.shape[0]\n",
    "    M = cp.Variable((2*n,2*n),PSD=True)\n",
    "    M1 = cp.Variable((n,n),PSD=True)\n",
    "    M2 = cp.Variable((n,n),PSD=True)\n",
    "    C_K = 2*cp.hstack([E1_K,-E2_K])\n",
    "    t = cp.Variable()\n",
    "    s = cp.Variable(nonneg=True)\n",
    "    u = cp.Variable(nonneg=True)   # epigraph variable for objective\n",
    "\n",
    "    # Constraints\n",
    "    constraints = []\n",
    "    constraints += [M - s * np.eye(2*n) >> 0]    # M >= s I  => s <= lambda_min(M)\n",
    "    constraints += [t == cp.trace((M1+M2)@Sigma_0)]      # linear relation\n",
    "    t_tilde = t / (np.sqrt(2.0) * lambda_)\n",
    "    # rotated SOC form: || [2*t_tilde; u - s] ||_2 <= u + s\n",
    "    constraints += [cp.norm(cp.vstack([2*t_tilde, u - s]), 2) <= u + s]  \n",
    "    constraints += [s>=1e-6,M>>C_K.T@C_K,A_K.T@M@A_K<<(1-2*lambda_)*M] #M>=1e-5*np.eye(2*n),\n",
    "    constraints += [M[:n,:n]==M1,M[n:,n:]==M2]\n",
    "\n",
    "    objective = cp.Minimize(u)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS) \n",
    "\n",
    "    if prob.status not in [\"infeasible\", \"unbounded\"]:\n",
    "        M = np.round(M.value)\n",
    "        M1 = np.round(M1.value,10)\n",
    "        M2 = np.round(M2.value,10)\n",
    "        bound = prob.value  \n",
    "        return bound\n",
    "    else:\n",
    "        raise ValueError(\"Problem status: \" + prob.status)\n",
    "\n",
    "def all_grad_heter_bisim_bounds(K,Sigma_0,As,Bs,Qs,Rs):\n",
    "    H = len(As)\n",
    "    result = np.zeros((H,H))\n",
    "    for i in range(H):\n",
    "        for j in range(i+1,H):\n",
    "            print(\"i,j:\",i,j)\n",
    "            result[i,j] = np.sqrt(squared_grad_heter_bisim_bound(K,Sigma_0,As[i],Bs[i],Qs[i],Rs[i],As[j],Bs[j],Qs[j],Rs[j]))\n",
    "    return result\n",
    "\n",
    "# Previous grad-cost heterogeneity matrix\n",
    "def spectral_norm(M):\n",
    "    return np.linalg.norm(M, 2)\n",
    "\n",
    "def max_spectral_norm(mats):\n",
    "    return max(spectral_norm(M) for M in mats)\n",
    "\n",
    "def grad_heter_prev_bound(K, As, Bs, Qs, Rs, Sigma_0, epsilons):\n",
    "    # Compute max cost over all system tuples\n",
    "    J_max = max(lqr_cost_K(Sigma_0, Ai, Bi, Qi, Ri, K) for Ai, Bi, Qi, Ri in zip(As, Bs, Qs, Rs))\n",
    "\n",
    "    # Minimum singular value of Q in Qs (smallest among all)\n",
    "    sigma_min_Qi = min(np.linalg.svd(Qi, compute_uv=False)[-1] for Qi in Qs)\n",
    "\n",
    "    mu = np.min(np.linalg.eigvalsh(Sigma_0))\n",
    "\n",
    "    nu = J_max / (sigma_min_Qi * mu)\n",
    "\n",
    "    # Compute P_K^i for each system i\n",
    "    PKs = [solve_discrete_lyapunov((Ai - Bi @ K).T, Qi + K.T @ Ri @ K) for Ai, Bi, Qi, Ri in zip(As, Bs, Qs, Rs)]\n",
    "    norm_PK_max = max_spectral_norm(PKs)  # <-- use max norm over all PKs\n",
    "\n",
    "    # Max spectral norms over all sets\n",
    "    norm_A_max = max_spectral_norm(As)\n",
    "    norm_B_max = max_spectral_norm(Bs)\n",
    "    norm_Q_max = max_spectral_norm(Qs)\n",
    "    norm_R_max = max_spectral_norm(Rs)\n",
    "\n",
    "    norm_A_minus_BK_max = max(\n",
    "        spectral_norm(Ai - Bi @ K) for Ai, Bi in zip(As, Bs))\n",
    "\n",
    "    norm_K = spectral_norm(K)\n",
    "    norm_Sigma_0 = spectral_norm(Sigma_0)\n",
    "\n",
    "    # h1_het(K)\n",
    "    h1 = (J_max / sigma_min_Qi) * norm_B_max * (\n",
    "        norm_PK_max + 4 * norm_A_minus_BK_max**2 * (norm_Q_max + norm_K**2 * norm_R_max) * nu**2)\n",
    "    h1 += 4 * (norm_R_max * norm_K +\n",
    "               (J_max * (norm_B_max**2 * norm_K + norm_B_max * norm_A_max)) / mu) * nu**2 * norm_A_minus_BK_max * norm_Sigma_0\n",
    "\n",
    "    # h2_het(K)\n",
    "    h2 = (J_max / sigma_min_Qi) * (\n",
    "        norm_A_minus_BK_max * norm_PK_max + norm_B_max * norm_PK_max * norm_K\n",
    "    + 4 * norm_K * norm_A_minus_BK_max**2 * (norm_Q_max + norm_K**2 * norm_R_max) * nu**2)\n",
    "    h2 += 4 * (norm_R_max * norm_K +\n",
    "               (J_max * (norm_B_max**2 * norm_K + norm_B_max * norm_A_max)) / mu) * nu**2 * norm_K * norm_A_minus_BK_max * norm_Sigma_0\n",
    "\n",
    "    # h3_het(K)\n",
    "    h3 = (J_max / sigma_min_Qi) * norm_B_max * norm_A_minus_BK_max * nu\n",
    "\n",
    "    # h4_het(K)\n",
    "    h4 = (J_max / sigma_min_Qi) * (norm_K + norm_K**2 * norm_B_max * norm_A_minus_BK_max * nu)\n",
    "\n",
    "    eps1, eps2, eps3, eps4 = epsilons\n",
    "    dx = As[0].shape[0]\n",
    "    du = Bs[0].shape[1]\n",
    "    bound = np.sqrt(min(dx,du)) * (eps1 * h1 + eps2 * h2 + eps3 * h3 + eps4 * h4)\n",
    "    return bound\n",
    "\n",
    "#Multitask-LQR (for negative feedback u=-Kx)\n",
    "def grad_true(Sigma_0,A,B,Q,R,K):\n",
    "    dx = A.shape[0]\n",
    "    PK = solve_discrete_lyapunov((A-B@K).T,Q+K.T@R@K)\n",
    "    EK = (R + B.T@PK@B)@K - B.T@PK@A\n",
    "    Sigma_K = solve_discrete_lyapunov(A-B@K,Sigma_0)\n",
    "    grad = 2*EK@Sigma_K\n",
    "    return grad\n",
    "\n",
    "def lqr_cost_K(Sigma_0,A,B,Q,R,K):\n",
    "        PK = solve_discrete_lyapunov((A-B@K).T,Q+K.T@R@K)\n",
    "        return np.trace(Sigma_0@PK)\n",
    "\n",
    "def lqr_cost_avg_K(Sigma_0,As,Bs,Qs,Rs,K):\n",
    "        H = len(As)\n",
    "        cost_avg = 0\n",
    "        for i in range(H):\n",
    "            cost_i = lqr_cost_K(Sigma_0,As[i],Bs[i],Qs[i],Rs[i],K)\n",
    "            cost_avg += (1/H)*cost_i\n",
    "        return cost_avg\n",
    "\n",
    "def grad_avg(As,Bs,Qs,Rs,K):\n",
    "    dx = As[0].shape[0]\n",
    "    du = Bs[0].shape[1]\n",
    "    H = len(As)\n",
    "    grad_avg = np.zeros((du,dx))\n",
    "    for i in range(H):\n",
    "        grad_cost_i = grad_true(Sigma_0,As[i],Bs[i],Qs[i],Rs[i],K)\n",
    "        grad_avg += (1/H)*grad_cost_i\n",
    "    return grad_avg\n",
    "\n",
    "def max_offdiag_norm(matrices):\n",
    "    N = len(matrices)\n",
    "    max_norm = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            diff_norm = np.linalg.norm(matrices[i] - matrices[j], ord=2)\n",
    "            if diff_norm > max_norm:\n",
    "                max_norm = diff_norm\n",
    "    return max_norm\n",
    "\n",
    "def compute_gener_error_bound(bisimbound, Jmax, Sigma_0, Rs, Qs):\n",
    "    # Minimum eigenvalue of Sigma_0\n",
    "    lambda_min = np.min(np.linalg.eigvals(Sigma_0)).real\n",
    "    \n",
    "    # Minimum singular value across all Ri\n",
    "    sigma_min_R = min(np.min(np.linalg.svd(Ri, compute_uv=False)) for Ri in Rs)\n",
    "    \n",
    "    # Minimum singular value across all Qi\n",
    "    sigma_min_Q = min(np.min(np.linalg.svd(Qi, compute_uv=False)) for Qi in Qs)\n",
    "    \n",
    "    # Compute the bound\n",
    "    bound = (2 * bisimbound**2 * Jmax) / (lambda_min**2 * sigma_min_R * sigma_min_Q)\n",
    "    return bound\n",
    "\n",
    "def multi_task_LQR(Js_star, Sigma_0, K0, eta, N, As, Bs, Qs, Rs):\n",
    "    K = K0\n",
    "    H = len(As)\n",
    "    Ks = []\n",
    "    grad_heter = []\n",
    "    bisim_grad_heter = []\n",
    "    prev_grad_heter = []\n",
    "    Js_Ks = np.zeros((H,N))\n",
    "    gener_error_bounds = []\n",
    "    costs_avg = []\n",
    "    bisim_bounds = np.zeros((H,N))\n",
    "\n",
    "    eps1 = max_offdiag_norm(As)\n",
    "    eps2 = max_offdiag_norm(Bs)\n",
    "    eps3 = max_offdiag_norm(Qs)\n",
    "    eps4 = max_offdiag_norm(Rs)\n",
    "    epsilons = (eps1, eps2, eps3, eps4)\n",
    "\n",
    "    x_vals = np.arange(N)  # fixed x-axis\n",
    "\n",
    "    for n in range(N):\n",
    "        Ks.append(K)\n",
    "        cost_avg = lqr_cost_avg_K(Sigma_0, As, Bs, Qs, Rs, K)\n",
    "        costs_avg.append(cost_avg)\n",
    "        grad_average = grad_avg(As, Bs, Qs, Rs, K)\n",
    "        for i in range(H):\n",
    "            Js_Ks[i,n] = lqr_cost_K(Sigma_0, As[i], Bs[i], Qs[i], Rs[i], K)  \n",
    "\n",
    "        grads_true = np.stack([grad_true(Sigma_0, As[i], Bs[i], Qs[i], Rs[i], K) for i in range(H)])\n",
    "        diffs = grads_true[:, None, :, :] - grads_true[None, :, :, :]\n",
    "        grad_heter.append(np.max(np.linalg.norm(diffs, axis=(2, 3))))\n",
    "        bisim_matrix = all_grad_heter_bisim_bounds(K, Sigma_0, As, Bs, Qs, Rs)\n",
    "        bisimbound = (1/H)*np.max(np.sum(bisim_matrix+bisim_matrix.T, axis=0))\n",
    "        print(\"bisim_matrix:\",bisim_matrix)\n",
    "        bisim_grad_heter.append(bisimbound)\n",
    "        prev_grad_heter.append(grad_heter_prev_bound(K, As, Bs, Qs, Rs, Sigma_0, epsilons))\n",
    "        gener_error_bounds.append(compute_gener_error_bound(bisimbound, max(Js_Ks[:,n]), Sigma_0, Rs, Qs))\n",
    "\n",
    "        K = K - eta * grad_average\n",
    "\n",
    "        print(f\"Iteration: {n+1}, Avg cost: {cost_avg}\")\n",
    "        print(f\"Grad. heter.: {grad_heter[-1]}\")\n",
    "        print(f\"Bisim. grad. heter.: {bisim_grad_heter[-1]}\")\n",
    "        print(f\"Prev. grad. heter.: {prev_grad_heter[-1]}\")\n",
    "        print(\"---------\")\n",
    "\n",
    "        if n == N-1:\n",
    "            max_optim_err = np.max(Js_Ks[i,n]-Js_star[i])\n",
    "    return grad_heter, bisim_grad_heter, prev_grad_heter, bisim_bounds, max_optim_err, Js_Ks, bisim_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample H tasks\n",
    "H = 6\n",
    "m_l_pairs = sample_m_l_pairs(H)\n",
    "q_r_pairs = sample_q_r_pairs(H)\n",
    "\n",
    "As = [inverted_pendulum(m, l)[0] for m, l in m_l_pairs]\n",
    "Bs = [inverted_pendulum(m, l)[1] for m, l in m_l_pairs]\n",
    "Qs = [q*np.eye(2) for q, r in q_r_pairs]\n",
    "Rs = [r*np.eye(1) for q, r in q_r_pairs]\n",
    "\n",
    "avg_sr = 0\n",
    "for i in range(H):\n",
    "    K = dlqr(As[i], Bs[i], Qs[i], Rs[i])\n",
    "    Acl = As[i] - Bs[i] @ K\n",
    "    sr = max(abs(np.linalg.eigvals(Acl)))\n",
    "    avg_sr += sr\n",
    "    print(f\"System {i+1}: spectral radius = {sr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = As[0].shape[0]\n",
    "Sigma_0 = 0.1*np.eye(dx)\n",
    "eta = 1e-2\n",
    "idx = 0\n",
    "K0 = 0\n",
    "for idx in range(H):\n",
    "    Kopt, _, _ = control.dlqr(As[idx], Bs[idx], Qs[idx], Rs[idx])\n",
    "    K0 += Kopt + 1 * np.random.randn(1,2)\n",
    "K0 *= 1/H\n",
    "\n",
    "Js_star = []\n",
    "for i in range(len(As)):\n",
    "    assert max(abs(np.linalg.eigvals(As[i] - Bs[i] @ K0))) < 1, \"K0 is not a common stabilizing controller\"\n",
    "    _, Pi_star, _ = control.dlqr(As[i], Bs[i], Qs[i], Rs[i])\n",
    "    Js_star.append(np.trace(Sigma_0@Pi_star))\n",
    "\n",
    "    \n",
    "N = 1000\n",
    "eps1 = max_offdiag_norm(As)\n",
    "eps2 = max_offdiag_norm(Bs)\n",
    "eps3 = max_offdiag_norm(Qs)\n",
    "eps4 = max_offdiag_norm(Rs)\n",
    "epsilons = (eps1, eps2, eps3, eps4)\n",
    "print(\"epsilons:\",epsilons)\n",
    "grad_heter, bisim_grad_heter, prev_grad_heter, bisim_bounds, max_optim_err, Js_Ks, bisim_bounds = multi_task_LQR(Js_star, Sigma_0, K0, eta, N, As, Bs, Qs, Rs)\n",
    "print(\"epsilons:\",epsilons)\n",
    "print(\"Maximum epsilon:\",max(epsilons))\n",
    "print(\"prev_grad_heter_infty:\",prev_grad_heter[-1])\n",
    "print(\"d_infty:\", np.max(bisim_bounds[:,-1]))\n",
    "print(\"max_task_specific_optim_error_infty:\",max_optim_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
